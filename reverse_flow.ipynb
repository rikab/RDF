{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f41362d7-5d19-4973-86c5-4b7d66467117",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH VERSION: 2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import io\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "print(f'TORCH VERSION: {torch.__version__}')\n",
    "import packaging.version\n",
    "if packaging.version.parse(torch.__version__) < packaging.version.parse('1.5.0'):\n",
    "    raise RuntimeError('Torch versions lower than 1.5.0 not supported')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0115d2a4-4b05-4596-8acd-f24976f9b7eb",
   "metadata": {},
   "source": [
    "Code is an amalgamation of https://arxiv.org/pdf/2101.08176 and https://github.com/TinyVolt/normalizing-flows/blob/main/1d_composing_flows/ComposableFlows1d.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ddea7c",
   "metadata": {},
   "source": [
    "# Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2d772537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physics Params\n",
    "E0 = 500            # Energy of Hard Process\n",
    "Lambda_QCD = 0.2    # Lambda QCD\n",
    "cutoff = 0.01      # Cutoff for minimum lambda, ~ LambdaQCD / E0\n",
    "\n",
    "\n",
    "# Training Params\n",
    "num_epochs = 1500\n",
    "lr = .01\n",
    "batch_size = 512\n",
    "num_points = 50 # we define a prior on each point along the horizontal axis\n",
    "                # eventually this should be made large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98b84b0e-8f42-47c7-953d-297bfcef664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH DEVICE: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch_device = 'cuda'\n",
    "    float_dtype = np.float32 # single\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    torch_device = 'cpu'\n",
    "    float_dtype = np.float64 # double\n",
    "    torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "    print(f\"TORCH DEVICE: {torch_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cfccfbf1-10ec-434c-b987-559c84ea95ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grab(var):\n",
    "    return var.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290df74b-c807-45eb-82ea-f3bc14cffaf8",
   "metadata": {},
   "source": [
    "## Define a prior distribution\n",
    "\n",
    "\n",
    "Standard normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "676cdbbe-dab8-4203-abf6-92e071188533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleNormal:\n",
    "    def __init__(self, loc, var):\n",
    "        self.dist = torch.distributions.normal.Normal(\n",
    "        torch.flatten(loc), torch.flatten(var))\n",
    "        self.shape = loc.shape\n",
    "    def log_prob(self, x):\n",
    "        logp = self.dist.log_prob(x.reshape(x.shape[0], -1))\n",
    "        return logp\n",
    "    def sample_n(self, batch_size):\n",
    "        x = self.dist.sample((batch_size,))\n",
    "        return x.reshape(batch_size, *self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf0f59b-69ab-4ac1-b773-39aec0cab808",
   "metadata": {},
   "source": [
    "# Define the flow\n",
    "\n",
    "Very simple 1-dimensional layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d39a1b08-7368-4b94-99ed-1d5cdb9e9f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.normal import Normal \n",
    "\n",
    "class Flow1d(nn.Module):\n",
    "    def __init__(self, n_components):\n",
    "        super(Flow1d, self).__init__()\n",
    "        self.mus = nn.Parameter(torch.randn(n_components), requires_grad=True)\n",
    "        self.log_sigmas = nn.Parameter(torch.zeros(n_components), requires_grad=True)\n",
    "        self.weight_logits = nn.Parameter(torch.ones(n_components), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,1)\n",
    "        weights = self.weight_logits.softmax(dim=0).view(1,-1)\n",
    "        distribution = Normal(self.mus, self.log_sigmas.exp())\n",
    "        z = (distribution.cdf(x) * weights).sum(dim=1)\n",
    "        log_dz_by_dx = (distribution.log_prob(x).exp() * weights).sum(dim=1).log()\n",
    "        return z, log_dz_by_dx\n",
    "    \n",
    "    def reverse(self, z):\n",
    "\n",
    "        z = z.view(-1,1)\n",
    "        weights = self.weight_logits.softmax(dim=0).view(1,-1)\n",
    "        distribution = Normal(self.mus, self.log_sigmas.exp())\n",
    "        x = distribution.icdf(z / weights.sum(dim=1, keepdim=True)).sum(dim=1)\n",
    "        x = torch.nan_to_num(x)\n",
    "        return x\n",
    "\n",
    "class LogitTransform(nn.Module):\n",
    "    def __init__(self, alpha):\n",
    "        super(LogitTransform, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_new = (self.alpha/2 + (1-self.alpha)*x).to(torch_device)\n",
    "        z = torch.log(x_new) - torch.log(1-x_new)\n",
    "        log_dz_by_dx = torch.log(torch.FloatTensor([1-self.alpha]).to(torch_device)) - torch.log(x_new) - torch.log(1-x_new)\n",
    "        return z, log_dz_by_dx\n",
    "    \n",
    "    def reverse(self, z):\n",
    "        x_new = torch.sigmoid(z)\n",
    "        x = (x_new - self.alpha/2) / (1-self.alpha)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class FlowComposable1d(nn.Module):\n",
    "    def __init__(self, flow_models_list):\n",
    "        super(FlowComposable1d, self).__init__()\n",
    "        self.flow_models_list = nn.ModuleList(flow_models_list).to(torch_device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, sum_log_dz_by_dx = x, 0\n",
    "        for flow in self.flow_models_list:\n",
    "            z, log_dz_by_dx = flow(z)\n",
    "            sum_log_dz_by_dx += log_dz_by_dx\n",
    "        return z, sum_log_dz_by_dx\n",
    "    \n",
    "    def reverse(self, z):\n",
    "        x = z\n",
    "        for flow in reversed(self.flow_models_list):\n",
    "            x = flow.reverse(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b06ea4f5-652c-4599-b2b3-1f4ab0a15c50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "\n",
    "# # toy model\n",
    "# def target_logp_order1(x): # 1st order approximation to the function\n",
    "\n",
    "#     target_p = 1.5*(-x**2 + 1)\n",
    "\n",
    "#     return torch.log(target_p)\n",
    "# # \"\"\"\n",
    "def calc_dkl(logp, logq):\n",
    "    return (logq - logp).mean() # reverse KL, assuming samples from q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc01191-e0b3-4cb2-98c0-056ca2f8a96d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define the probability density "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "624aba29-c0b8-4669-a54b-b9eb11745847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def alpha_s(scale):\n",
    "    lambda_qcd = 0.2\n",
    "    beta_0 = 11 - 2/3 * 3\n",
    "    return 4 * np.pi / (beta_0 * torch.log(scale**2 / lambda_qcd**2))\n",
    "\n",
    "def target_logp_order1(x): # 1st order approximation to the function\n",
    "\n",
    "    alpha_s_scale = alpha_s(x * E0) # GeV\n",
    "    C_F = 4/3\n",
    "    C_A = 3\n",
    "    \n",
    "    p_order1 = -(alpha_s_scale * C_F / (1 * np.pi)) * torch.log(x ) / x\n",
    "        \n",
    "    p_order1[x < cutoff] = 0\n",
    "\n",
    "    # # normalize so the integral is 1\n",
    "    # dx = x[1] - x[0]\n",
    "    # p_order1 = p_order1 / p_order1.sum()  / dx\n",
    "        \n",
    "    log_p_order1 = torch.log(p_order1)\n",
    "        \n",
    "    \n",
    "\n",
    "    return torch.nan_to_num(log_p_order1, nan = 0.0)\n",
    "\n",
    "# # \"\"\"\n",
    "# # toy model\n",
    "# def target_logp_order1(x): # 1st order approximation to the function\n",
    "\n",
    "#     target_p = 1.5*(-x**2 + 1)\n",
    "\n",
    "#     return torch.log(target_p)\n",
    "# # \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63528e",
   "metadata": {},
   "source": [
    "# Model Initialization and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a07e831-8bc5-4074-a31f-bd02b535759c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "\n",
    "    # Initialize the prior\n",
    "    prior = SimpleNormal(torch.zeros(num_points), torch.ones(num_points))\n",
    "\n",
    "    # Initialize the model\n",
    "    # Model archutecture not optimized at all\n",
    "    flow_models_list = [Flow1d(2), LogitTransform(0.1), Flow1d(2), LogitTransform(0.1), Flow1d(2)]\n",
    "    flow = FlowComposable1d(flow_models_list)\n",
    "    optimizer = torch.optim.Adam(flow.parameters(), lr=lr)\n",
    "\n",
    "    return flow, optimizer, prior\n",
    "\n",
    "\n",
    "def train_model(lambda_star):\n",
    "\n",
    "    train_losses = []\n",
    "    flow, optimizer, prior = initialize_model()\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "\n",
    "        # Generate a bunch of random samples xs, calculate p(xs)\n",
    "        xs = torch.rand((batch_size, num_points)).to(torch_device)\n",
    "        log_p = target_logp_order1(xs)\n",
    "\n",
    "        # Calculate q(xs) using the reverse flow\n",
    "        zs_from_xs = flow.reverse(xs)\n",
    "        print(zs_from_xs)\n",
    "        log_q = prior.log_prob(zs_from_xs)\n",
    "        x_prime, logJ = flow(zs_from_xs)\n",
    "        print(x_prime.shape, xs.shape)\n",
    "        print(log_q.shape, logJ.shape, log_p.shape)\n",
    "        log_q = log_q - logJ\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # Weighted KL divergence\n",
    "        p = torch.exp(log_p)\n",
    "        loss = torch.mean(p * (log_p - log_q))\n",
    "\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        train_losses.append(grab(loss))\n",
    "\n",
    "\n",
    "    return flow, train_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2acbca23-9bc0-4474-91b5-4cfb2a784222",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 1.5437, 0.0000,  ..., 1.6410, 1.6410, 1.6410],\n",
      "       grad_fn=<NanToNumBackward0>)\n",
      "torch.Size([25600]) torch.Size([512, 50])\n",
      "torch.Size([25600, 50]) torch.Size([25600]) torch.Size([512, 50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (50) must match the size of tensor b (25600) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lambda_star \u001b[38;5;129;01min\u001b[39;00m lambda_stars:\n\u001b[0;32m----> 6\u001b[0m     flow, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambda_star\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     flows\u001b[38;5;241m.\u001b[39mappend(flow)\n\u001b[1;32m      8\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[78], line 35\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(lambda_star)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_prime\u001b[38;5;241m.\u001b[39mshape, xs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(log_q\u001b[38;5;241m.\u001b[39mshape, logJ\u001b[38;5;241m.\u001b[39mshape, log_p\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 35\u001b[0m log_q \u001b[38;5;241m=\u001b[39m \u001b[43mlog_q\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogJ\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Weighted KL divergence\u001b[39;00m\n\u001b[1;32m     41\u001b[0m p \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(log_p)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (50) must match the size of tensor b (25600) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "lambda_stars = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "flows = []\n",
    "train_losses = []\n",
    "\n",
    "for lambda_star in lambda_stars:\n",
    "    flow, train_loss = train_model(lambda_star)\n",
    "    flows.append(flow)\n",
    "    train_losses.append(train_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e532cd39-fa7b-4c02-ac64-1e57fa8f7c67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, lambda_star \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lambda_stars[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m----> 4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_losses\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda_star = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlambda_star\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, color \u001b[38;5;241m=\u001b[39m (i\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(lambda_stars), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda_star = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlambda_star\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, losses = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_losses[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "for i, lambda_star in enumerate(lambda_stars[::-1]):\n",
    "    plt.plot(train_losses[i], label = f\"lambda_star = {lambda_star}\", color = (i/len(lambda_stars), 0, 0))\n",
    "    print(f\"lambda_star = {lambda_star}, losses = {train_losses[i]}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Train loss\")\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5046d445-6ab7-473b-a9c1-be3ac711930b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m prior \u001b[38;5;241m=\u001b[39m SimpleNormal(torch\u001b[38;5;241m.\u001b[39mzeros(num_points), torch\u001b[38;5;241m.\u001b[39mones(num_points))\n\u001b[1;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m prior\u001b[38;5;241m.\u001b[39msample_n(batch_size)\u001b[38;5;241m.\u001b[39mto(torch_device) \u001b[38;5;66;03m# shape x: (batch_size, num_points)    \u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m x, logJ \u001b[38;5;241m=\u001b[39m \u001b[43mflow\u001b[49m(x)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# need to reshape the outputs match those from the previous step\u001b[39;00m\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m grab(x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m) )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flow' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot output\n",
    "\n",
    "for (i, lambda_star) in enumerate(lambda_stars):\n",
    "\n",
    "    x_test = torch.linspace(0, 1, 1000)\n",
    "\n",
    "\n",
    "    plt.figure(figsize = (8,8))\n",
    "\n",
    "    # plot the target\n",
    "    y_test = np.exp(grab(target_logp_order1(x_test.to(torch_device)))) \n",
    "    y_test = y_test / np.sum(y_test) / (x_test[1] - x_test[0]) \n",
    "    plt.plot(grab(x_test), y_test , label = \"Leading Order Target\", color = \"black\", lw = 3)\n",
    "\n",
    "    # plot transformed prior\n",
    "    prior = SimpleNormal(torch.zeros(num_points), torch.ones(num_points))\n",
    "    x = prior.sample_n(batch_size).to(torch_device) # shape x: (batch_size, num_points)    \n",
    "    x, logJ = flow(x)\n",
    "    # need to reshape the outputs match those from the previous step\n",
    "    x = grab(x.reshape(-1,1) )\n",
    "\n",
    "\n",
    "    plt.hist(x, bins = np.linspace(0, 1, 100), density = True, label = \"Learned Samples\", histtype='step', color = \"red\", lw = 3)\n",
    "\n",
    "\n",
    "    # Plot the samples as a baseline\n",
    "    np_angularities = np.load(\"normalized_angularity.npy\")\n",
    "    plt.hist(np_angularities, bins = np.linspace(0, 1, 100), density = True, label = \"Pythia Samples\", histtype='step', color = \"pink\", lw = 3)\n",
    "\n",
    "    # Vertical line at lambda_star\n",
    "    plt.axvline(lambda_star, color = \"black\", linestyle = \"--\", label = r\"$\\lambda^*$\")\n",
    "\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(frameon = False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1adbf8a-fa79-482a-891d-df94d2fafa31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c2a76-83bd-4a49-b40c-f847076a691a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797b49a1-85f8-4461-ba83-b758f0e17d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f439f02-e7fe-456b-807a-ed95d6de79d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec738574-6b11-4879-b7e8-d9cdd199f799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7072d4-03f4-4000-9c56-c190df063a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155769ad-5a56-4cf5-816a-977e97d7999c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8abd870-5f71-472b-b7ef-9934560eed3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d2647-db4d-46a0-a8ac-667409bdb71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f455467-079b-4f00-8867-30c04edbe851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f00c7a-1e1e-42ce-abb8-b9f755f3a0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2263ac6-1a16-4141-86f1-17e3dc60ea4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f62e9c4-69dc-4b89-aece-939aed2e67b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9964078-905c-4039-baf1-3ec5f983fc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d82cb-a838-494e-b2bc-ec6c1c66d9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16bc81-6dd3-43db-8255-f434c988ce1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
